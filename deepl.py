import os
import re
import pandas as pd
from dotenv import load_dotenv

import clickhouse_driver
import openai

# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
from langchain_openai import ChatOpenAI

# from langchain.embeddings import OpenAIEmbeddings
from langchain_openai import OpenAIEmbeddings
from langchain.llms import OpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.chains import RetrievalQA
from langchain.chains import create_sql_query_chain
from langchain.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate

from langchain_teddynote import logging
from langchain_community.utilities import SQLDatabase
from langchain.document_loaders import DataFrameLoader
from langchain_core.prompts import load_prompt
from langchain_core.prompts import ChatPromptTemplate

llm = ChatOpenAI(model_name="gpt-4o", temperature=0.1)

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ClickHouse ì ‘ì† ì •ë³´ ê°€ì ¸ì˜¤ê¸°
CLICKHOUSE_HOST = os.getenv("CLICKHOUSE_HOST")
CLICKHOUSE_PORTNATIVE = os.getenv("CLICKHOUSE_PORTNATIVE")  # ê¸°ë³¸ í¬íŠ¸ 9000 (NATIVE)
CLICKHOUSE_USER = os.getenv("CLICKHOUSE_USER")
CLICKHOUSE_PASSWORD = os.getenv("CLICKHOUSE_PASSWORD")
CLICKHOUSE_DATABASE = os.getenv("CLICKHOUSE_DATABASE")


# # í™˜ê²½ë³€ìˆ˜ ì´ˆê¸°í™”
def init_env():

    load_dotenv()

    # llm API ì„¤ì •
    llm = ChatOpenAI(model="gpt-4o", temperature=0.1)

    # LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com
    # í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.


#    logging.langsmith("DeepLens-01")
# openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)


def connect_to_clickhouse():
    """ClickHouseì— ì—°ê²°í•˜ê³  ì—°ê²° ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        driver = clickhouse_driver.Client(
            host=CLICKHOUSE_HOST,
            port=CLICKHOUSE_PORTNATIVE,
            database=CLICKHOUSE_DATABASE,
            user=CLICKHOUSE_USER,
            password=CLICKHOUSE_PASSWORD,
        )
        return driver
    except Exception as e:
        print(f"ClickHouse ì—°ê²° ì˜¤ë¥˜: {e}")
        return None


def get_tablemeta():
    """ClickHouse ì—°ê²°, ì •ë³´ ì¶”ì¶œ, FAISS ì¸ë±ìŠ¤ ìƒì„±, ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    db_driver = connect_to_clickhouse()
    if not db_driver:
        return

    """ClickHouse ë°ì´í„°ë² ì´ìŠ¤ì˜ í…Œì´ë¸” ë° ì»¬ëŸ¼ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        # í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        table_query = f"""
            SELECT a.name AS table_name,
                CAST(b.table_comment AS String) table_comment 
            FROM system.tables a 
            INNER JOIN information_schema.tables b 
                on a.database = '{CLICKHOUSE_DATABASE}'
            AND a.database = b.table_schema 
            AND a.name IN ('moniClckStream', 'userProfile', 'page-metadata')
            AND a.name = b.table_name
        """
        tables = db_driver.execute(table_query)

        table_meta = []
        for table in tables:
            table_name, table_comment = table
            table_comment = (
                table_comment.decode("utf-8", errors="replace")
                if isinstance(table_comment, bytes)
                else table_comment
            )

            columns_query = f"""
            SELECT column_name as column_name, data_type as column_type, CAST(column_comment AS String) as column_comment
            FROM information_schema.columns
            WHERE table_schema = '{CLICKHOUSE_DATABASE}' AND table_name = '{table_name}'
            """
            columns = db_driver.execute(columns_query)

            for col in columns:
                column_name, column_type, column_comment = col
                column_comment = (
                    column_comment.decode("utf-8", errors="replace")
                    if isinstance(column_comment, bytes)
                    else column_comment
                )
                table_meta.append(
                    {
                        "table_name": table_name,
                        "table_comment": table_comment if table_comment else "",
                        "column_name": column_name,
                        "column_comment": column_comment if column_comment else "",
                        "column_type": column_type,
                        # "description": f"Table: {table_name}, Column: {column_name}, Type: {column_type}"
                        "description": f"Table: {table_name} ({table_comment}), Column: {column_name} ({column_comment}), Type: {column_type}",
                    }
                )

        return pd.DataFrame(table_meta)

    except Exception as e:
        print(f"í…Œì´ë¸” ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return None


def get_templatequery():

    try:
        # ì‚¬ì „ ì •ì˜ëœ Sample Queries ë° í•œê¸€ ì„¤ëª… ì¶”ê°€
        sample_template_queries = [
            {
                "query": """
                SELECT T1.accesstime,
                    toDateTime(T1.accesstime) action_time,
                    T1.pcid,
                    T1.nthsessionid,
                    T1.url,
                    T1.pageid,
                    T1.pagetitle,
                    T1.tagtype,
                    T1.clicktext
                FROM moniClckStream T1
                LEFT OUTER JOIN page_metadata T2
                    ON T1.pageid = T2.page_id
                AND T1.siteid = T2.site_id
               -- LEFT OUTER JOIN userProfile T3
               --     ON T1.memberid = T3.memberId
                WHERE T1.pagetitle LIKE '%%'    
                -- AND T1.memberid = '10000001'
                AND toDate(T1.accesstime) between '2025-04-01' AND today()
                AND T1.siteid = 'KNBANK'
                LIMIT 30
                ;    
            """,
                "description": "íŠ¹ì •í˜ì´ì§€ë¥¼ ë°©ë¬¸í•œ ê³ ê°ì˜ í–‰ë™ë°ì´í„° ì¶”ì¶œ ì¿¼ë¦¬",
            }
        ]

        return pd.DataFrame(sample_template_queries)

    except Exception as e:
        print(f"Template Query ë“±ë¡ ì—ëŸ¬: {e}")
        return None


def execute_query(input_query):
    """ClickHouse ì—°ê²°, ì •ë³´ ì¶”ì¶œ, FAISS ì¸ë±ìŠ¤ ìƒì„±, ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    db_driver = connect_to_clickhouse()
    if not db_driver:
        return

    try:
        query_exec_list = db_driver.execute(input_query)
        # result = analysis_target(target_list)
        # df = pd.DataFrame(result)
        # print(query_exec_list)
        return query_exec_list
    except Exception as e:
        print(f"ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

    else:
        return None


def set_request_prompt(user_input):

    prompt_template = load_prompt("prompts/analysis1.yaml", encoding="utf-8")

    df_query_script = get_templatequery()

    table_meta = get_tablemeta()

    query_result = execute_query(df_query_script["query"][0])

    prompt = prompt_template.format(
        table_meta=table_meta,
        query_script=df_query_script,
        query_result=query_result,
        user_input=user_input,
    )

    return prompt


def analysis_target(input_query_result):
    # LLMì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ ê²°ê³¼ ë¶„ì„ ìš”ì²­

    analysis_prompt = """
    ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ê³ ê°ì˜ í–‰ë™ìˆ˜ì§‘í•˜ê³  ì˜ë¯¸ìˆëŠ” í–‰ë™ì„ ì°¾ì•„ë‚´ì„œ ë§ˆì¼€íŒ…ì„±ê³¼ë¥¼ ëŒì–´ë‚´ëŠ” ì „ì„¸ê³„ì—ì„œ ê°€ì¥ ìœ ëŠ¥í•œ ê³ ê°í–‰ë™ë°ì´í„° AIë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ë‹¤ìŒì€ íŠ¹ì • ê³ ê°ì˜ í–‰ë™ë°ì´í„°ë¡œ ì´ ë°ì´í„°ë¥¼ ìš”ì•½í•˜ê³ , [FORMAT]ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”.

    #ì¡°íšŒê²°ê³¼:
    {query_result}

    #FORMAT:
    - ì „ì²´ê±´ìˆ˜:
    - ì£¼ìš”ë°©ë¬¸í˜ì´ì§€:
    - ì‹œê°„ë³„ ì²´ë¥˜ì‹œê°„ ë° ì´ì²´ë¥˜ì‹œê°„(ì‹œê°„ì€ datetime_action ì •ë³´ì´ìš©):
    - ì´ë™ê²½ë¡œ ìˆœì„œë„ìš”ì•½(ìˆœì„œ,í˜ì´ì§€,ë°©ë¬¸ì‹œê°„):
    - ê³ ê°ì¶”ì²œìƒí’ˆ(ìµœë¹ˆë„ìˆœìœ„3ê°œ):
    """

    prompt = PromptTemplate.from_template(analysis_prompt)

    # LLMì„ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ ìš”ì•½ ë° ë¶„ì„ ìš”ì²­
    chain = prompt | llm

    input = {"query_result": input_query_result}

    analysis_result = chain.invoke(input)

    return analysis_result
    # # print("\nğŸ”¹ LLM ë¶„ì„ ê²°ê³¼:\n", analysis_result)


def get_retriever(df_tablemeta, df_templatequery):
    """í…Œì´ë¸” ë° ì»¬ëŸ¼ ì •ë³´ë¥¼ FAISSì— ì €ì¥í•©ë‹ˆë‹¤."""
    combined_df = pd.concat([df_tablemeta, df_templatequery], ignore_index=True)

    loader = DataFrameLoader(combined_df, page_content_column="description")

    docs = loader.load()
    vectorstore = FAISS.from_documents(docs, OpenAIEmbeddings())
    # retriever = vectorstore.as_retriever()

    return vectorstore.as_retriever(
        search_kwargs={"k": 5}
    )  # ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìœ„í•œ kê°’ ì„¤ì •


def split_question(question):
    """
    ì£¼ì–´ì§„ ì§ˆë¬¸ì„ 'ë¶„ì„í•  ëŒ€ìƒì˜ ì¡°ê±´'ê³¼ 'ë¶„ì„ ì£¼ì œ'ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.

    ì§€ì›í•˜ëŠ” íŒ¨í„´:
    1) "Aì˜ B" -> "VIP ê³ ê°ì˜ í‰ê·  êµ¬ë§¤ ê¸ˆì•¡ì„ ì•Œë ¤ì¤˜"
    2) "Aí•œ ê³ ê°ì˜ B" -> "íšŒì› ê°€ì…í•œ ê³ ê°ì˜ ì¬ë°©ë¬¸ìœ¨ì„ ë¶„ì„í•´ì¤˜"
    3) "Aì— ëŒ€í•œ B" -> "íšŒì› ë“±ê¸‰ì— ëŒ€í•œ êµ¬ë§¤ íŒ¨í„´ì„ ë¶„ì„í•´ì¤˜"
    4) "Aì¸ ê³ ê° B" -> "ê³ ê°ë²ˆí˜¸ê°€ 11111ì¸ ê³ ê°ì˜ êµ¬ë§¤ íŒ¨í„´ì„ ë¶„ì„í•´ì¤˜"

    :param question: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸
    :return: (ëŒ€ìƒ ì¡°ê±´, ë¶„ì„ ì£¼ì œ)
    """

    patterns = [
        (re.compile(r"(.+?)ì˜ (.+)"), 1, 2),  # "Aì˜ B"
        (re.compile(r"(.+?í•œ ê³ ê°)ì˜ (.+)"), 1, 2),  # "Aí•œ ê³ ê°ì˜ B"
        (re.compile(r"(.+?)ì— ëŒ€í•œ (.+)"), 1, 2),  # "Aì— ëŒ€í•œ B"
        (re.compile(r"(.+?)ì¸ ê³ ê° (.+)"), 1, 2),  # "Aì¸ ê³ ê° B"
    ]

    for pattern, target_idx, subject_idx in patterns:
        match = pattern.match(question)
        if match:
            analysis_target = match.group(target_idx).strip()
            analysis_subject = match.group(subject_idx).strip()
            ans = True
            return ans, analysis_target, analysis_subject

    # ë¶„ë¦¬ê°€ ì•ˆ ë  ê²½ìš° ì „ì²´ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜

    return False, question, ""


# def split_sentence_AI(user_input):
#     """
#     ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ GPT-4oë¥¼ í†µí•´ ë¶„ì„í•˜ì—¬
#     1. ê³ ê° ì¶”ì¶œ ì¡°ê±´
#     2. ê²°ê³¼ ìš”ì²­ ì‚¬í•­
#     ë‘ ê°œì˜ ìš”ì•½ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
#     """

#     prompt = f"""
#     ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¬¸ì¥ì„ ë‘ ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”:
#     1. ê³ ê° ì¶”ì¶œ ì¡°ê±´ (ì˜ˆ: ê³ ê°ì„ í•„í„°ë§í•˜ëŠ” ê¸°ì¤€)
#     2. ê²°ê³¼ ìš”ì²­ ì‚¬í•­ (ì˜ˆ: ê³ ê° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì‘ì—…)

#     ì˜ˆì œ ì…ë ¥: "ê³ ê°ë²ˆí˜¸ê°€ 111ì¸ ê³ ê°ì˜ ì¶”ì²œìƒí’ˆì„ ì„ ì •í•´ì¤˜"
#     ì˜ˆì œ ì¶œë ¥:
#     ê³ ê° ì¶”ì¶œ ì¡°ê±´: ê³ ê°ë²ˆí˜¸ê°€ 111ì¸ ê³ ê°
#     ê²°ê³¼ ìš”ì²­ ì‚¬í•­: ì¶”ì²œìƒí’ˆì„ ì„ ì •í•´ì¤˜

#     ì…ë ¥: "{user_input}"
#     ì¶œë ¥:
#     """

#     # âœ… ìµœì‹  OpenAI SDK ë°©ì‹
#     response = openai_client.chat.completions.create(
#         model="gpt-4o",
#         messages=[
#             {
#                 "role": "system",
#                 "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ëŠ” AIì…ë‹ˆë‹¤.",
#             },
#             {"role": "user", "content": prompt},
#         ],
#     )

#     # ğŸ”¹ GPT ì‘ë‹µì—ì„œ ê²°ê³¼ ì¶”ì¶œ
#     result_text = response.choices[0].message.content
#     lines = result_text.split("\n")

#     # ğŸ”¹ ê²°ê³¼ê°’ ì´ˆê¸°í™”
#     condition, request = "", ""

#     for line in lines:
#         if "ê³ ê° ì¶”ì¶œ ì¡°ê±´:" in line:
#             condition = line.replace("ê³ ê° ì¶”ì¶œ ì¡°ê±´:", "").strip()
#         elif "ê²°ê³¼ ìš”ì²­ ì‚¬í•­:" in line:
#             request = line.replace("ê²°ê³¼ ìš”ì²­ ì‚¬í•­:", "").strip()

#     return condition, request
